{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d04597d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found classes: ['Astrocitoma', 'Carcinoma', 'Ependimoma', 'Ganglioglioma', 'Germinoma', 'Glioblastoma', 'Granuloma', 'Meduloblastoma', 'Meningioma', 'NORMAL', 'Neurocitoma', 'Oligodendroglioma', 'Papiloma', 'Schwannoma', 'Tuberculoma']\n",
      "Model for Astrocitoma already exists. Skipping...\n",
      "Model for Carcinoma already exists. Skipping...\n",
      "Model for Ependimoma already exists. Skipping...\n",
      "Model for Ganglioglioma already exists. Skipping...\n",
      "Model for Germinoma already exists. Skipping...\n",
      "Model for Glioblastoma already exists. Skipping...\n",
      "Model for Granuloma already exists. Skipping...\n",
      "Model for Meduloblastoma already exists. Skipping...\n",
      "Model for Meningioma already exists. Skipping...\n",
      "Model for NORMAL already exists. Skipping...\n",
      "Model for Neurocitoma already exists. Skipping...\n",
      "Model for Oligodendroglioma already exists. Skipping...\n",
      "Model for Papiloma already exists. Skipping...\n",
      "Model for Schwannoma already exists. Skipping...\n",
      "Model for Tuberculoma already exists. Skipping...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, mean_squared_error, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==== Hyperparameters and Paths ====\n",
    "DATA_DIR = Path(\"./dataset\")\n",
    "MODEL_SAVE_DIR = Path(\"./models_customcnn\")\n",
    "MODEL_SAVE_DIR.mkdir(exist_ok=True)\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "LR = 5e-4\n",
    "EPOCHS = 10\n",
    "NUM_WORKERS = 0 if os.name == 'nt' else 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# ==== Dataset Setup ====\n",
    "dirs = [d.name for d in DATA_DIR.iterdir() if d.is_dir()]\n",
    "class_names = sorted(dirs)\n",
    "num_classes = len(class_names)\n",
    "print(\"Found classes:\", class_names)\n",
    "\n",
    "class BinaryFolderDataset(Dataset):\n",
    "    def __init__(self, root_dir, positive_class, transform=None):\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        for cls_dir in Path(root_dir).iterdir():\n",
    "            if not cls_dir.is_dir():\n",
    "                continue\n",
    "            label = 1 if cls_dir.name == positive_class else 0\n",
    "            for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
    "                for img_path in cls_dir.glob(ext):\n",
    "                    self.samples.append((img_path, label))\n",
    "        if not self.samples:\n",
    "            raise RuntimeError(f\"No images found for class '{positive_class}' in {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# ==== Transforms ====\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# ==== Custom Lightweight CNN ====\n",
    "class LightTumorCNN(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(LightTumorCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2),  # 112x112\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),  # 56x56\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),  # 28x28\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2)  # 14x14\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x  # shape [B, 1]\n",
    "\n",
    "def create_binary_model():\n",
    "    model = LightTumorCNN(num_classes=1)\n",
    "    return model.to(device)\n",
    "\n",
    "# ==== Training/Evaluation Functions ====\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        y = y.unsqueeze(1).float()\n",
    "        loss = criterion(out, y)\n",
    "        preds = (torch.sigmoid(out) > 0.5).int()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        correct += (preds.view(-1) == y.view(-1)).sum().item()\n",
    "        total += x.size(0)\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    y_true, y_pred, y_prob = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            y = y.unsqueeze(1).float()\n",
    "            loss = criterion(out, y)\n",
    "            probs = torch.sigmoid(out)\n",
    "            preds = (probs > 0.5).int()\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "            correct += (preds.view(-1) == y.view(-1)).sum().item()\n",
    "            total += x.size(0)\n",
    "            y_true.append(y.view(-1).cpu())\n",
    "            y_pred.append(preds.view(-1).cpu())\n",
    "            y_prob.append(probs.view(-1).cpu())\n",
    "    y_true = torch.cat(y_true).numpy()\n",
    "    y_pred = torch.cat(y_pred).numpy()\n",
    "    y_prob = torch.cat(y_prob).numpy()\n",
    "    \n",
    "    acc = correct / total\n",
    "    mse = mean_squared_error(y_true, y_prob)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    errors = np.sum(y_true != y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"loss\": running_loss / total,\n",
    "        \"acc\": acc,\n",
    "        \"mse\": mse,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"errors\": errors,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred\n",
    "    }\n",
    "\n",
    "\n",
    "def create_balanced_loader(dataset, indices, batch_size, num_workers):\n",
    "    targets = [dataset.samples[i][1] for i in indices]\n",
    "    class_sample_count = np.bincount(targets)\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in targets])\n",
    "    sampler = WeightedRandomSampler(samples_weight, num_samples=len(samples_weight), replacement=True)\n",
    "    loader = DataLoader(Subset(dataset, indices), batch_size=batch_size, sampler=sampler, num_workers=num_workers)\n",
    "    return loader\n",
    "\n",
    "def save_binary_histories_to_csv(binary_histories, filename='binary_histories_customcnn.csv'):\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Class'] + [f\"Epoch {i+1}\" for i in range(len(next(iter(binary_histories.values()))))])\n",
    "        for cls, history in binary_histories.items():\n",
    "            writer.writerow([cls] + history)\n",
    "\n",
    "# ==== Training Binary Ensemble Models ====\n",
    "ensemble_models = {}\n",
    "binary_histories = {cls: [] for cls in class_names}\n",
    "\n",
    "for cls in class_names:\n",
    "    model_path = MODEL_SAVE_DIR / f\"best_binary_{cls}.pth\"\n",
    "    if model_path.exists():\n",
    "        print(f\"Model for {cls} already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n--- Training {cls} vs Rest ---\")\n",
    "    ds = BinaryFolderDataset(DATA_DIR, cls, transform=transform)\n",
    "    labels = [label for _, label in ds.samples]\n",
    "    \n",
    "    train_idx, temp_idx = train_test_split(range(len(ds)), test_size=0.3, stratify=labels)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, stratify=[labels[i] for i in temp_idx])\n",
    "    \n",
    "    train_loader = create_balanced_loader(ds, train_idx, BATCH_SIZE, NUM_WORKERS)\n",
    "    val_loader = DataLoader(Subset(ds, val_idx), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    test_loader = DataLoader(Subset(ds, test_idx), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    model = create_binary_model()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        val_metrics = eval_epoch(model, val_loader, criterion)\n",
    "        val_loss = val_metrics[\"loss\"]\n",
    "        val_acc = val_metrics[\"acc\"]\n",
    "        binary_histories[cls].append(val_acc)\n",
    "        save_binary_histories_to_csv(binary_histories)\n",
    "        print(f\"[{cls}] Epoch {epoch}: Val Acc = {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "    ensemble_models[cls] = model\n",
    "    print(f\"\\n--- Evaluation for {cls} ---\")\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    train_metrics = eval_epoch(model, train_loader, criterion)\n",
    "    val_metrics = eval_epoch(model, val_loader, criterion)\n",
    "    test_metrics = eval_epoch(model, test_loader, criterion)\n",
    "\n",
    "    def print_metrics(split, metrics):\n",
    "        print(f\"{split} Accuracy: {metrics['acc']:.4f}\")\n",
    "        print(f\"{split} Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"{split} Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"{split} F1 Score: {metrics['f1']:.4f}\")\n",
    "        print(f\"{split} MSE: {metrics['mse']:.4f}\")\n",
    "        print(f\"{split} Errors: {metrics['errors']}\")\n",
    "        print(f\"{split} Confusion Matrix:\\n{metrics['confusion_matrix']}\\n\")\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=metrics['confusion_matrix'], display_labels=[\"Other\", cls])\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title(f\"{split} Confusion Matrix for {cls}\")\n",
    "        plt.show()\n",
    "\n",
    "    print_metrics(\"Train\", train_metrics)\n",
    "    print_metrics(\"Validation\", val_metrics)\n",
    "    print_metrics(\"Test\", test_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58ed7a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Astrocitoma vs Rest ---\n",
      "\n",
      "--- Evaluation for Astrocitoma ---\n",
      "Train Accuracy: 0.5965\n",
      "Train Precision: 0.9550\n",
      "Train Recall: 0.1851\n",
      "Train F1 Score: 0.3101\n",
      "Train MSE: 0.2530\n",
      "Train Errors: 1228\n",
      "Train Confusion Matrix:\n",
      "[[1539   13]\n",
      " [1215  276]]\n",
      "\n",
      "Validation Accuracy: 0.8896\n",
      "Validation Precision: 0.9375\n",
      "Validation Recall: 0.1744\n",
      "Validation F1 Score: 0.2941\n",
      "Validation MSE: 0.0811\n",
      "Validation Errors: 72\n",
      "Validation Confusion Matrix:\n",
      "[[565   1]\n",
      " [ 71  15]]\n",
      "\n",
      "Test Accuracy: 0.8882\n",
      "Test Precision: 0.8095\n",
      "Test Recall: 0.1977\n",
      "Test F1 Score: 0.3178\n",
      "Test MSE: 0.0843\n",
      "Test Errors: 73\n",
      "Test Confusion Matrix:\n",
      "[[563   4]\n",
      " [ 69  17]]\n",
      "\n",
      "\n",
      "--- Training Carcinoma vs Rest ---\n",
      "\n",
      "--- Evaluation for Carcinoma ---\n",
      "Train Accuracy: 0.9415\n",
      "Train Precision: 0.9964\n",
      "Train Recall: 0.8882\n",
      "Train F1 Score: 0.9392\n",
      "Train MSE: 0.0603\n",
      "Train Errors: 178\n",
      "Train Confusion Matrix:\n",
      "[[1491    5]\n",
      " [ 173 1374]]\n",
      "\n",
      "Validation Accuracy: 0.9939\n",
      "Validation Precision: 0.9615\n",
      "Validation Recall: 0.8929\n",
      "Validation F1 Score: 0.9259\n",
      "Validation MSE: 0.0052\n",
      "Validation Errors: 4\n",
      "Validation Confusion Matrix:\n",
      "[[623   1]\n",
      " [  3  25]]\n",
      "\n",
      "Test Accuracy: 0.9954\n",
      "Test Precision: 1.0000\n",
      "Test Recall: 0.8929\n",
      "Test F1 Score: 0.9434\n",
      "Test MSE: 0.0055\n",
      "Test Errors: 3\n",
      "Test Confusion Matrix:\n",
      "[[625   0]\n",
      " [  3  25]]\n",
      "\n",
      "\n",
      "--- Training Ependimoma vs Rest ---\n",
      "\n",
      "--- Evaluation for Ependimoma ---\n",
      "Train Accuracy: 0.7795\n",
      "Train Precision: 0.9953\n",
      "Train Recall: 0.5615\n",
      "Train F1 Score: 0.7179\n",
      "Train MSE: 0.1578\n",
      "Train Errors: 671\n",
      "Train Confusion Matrix:\n",
      "[[1518    4]\n",
      " [ 667  854]]\n",
      "\n",
      "Validation Accuracy: 0.9831\n",
      "Validation Precision: 1.0000\n",
      "Validation Recall: 0.5000\n",
      "Validation F1 Score: 0.6667\n",
      "Validation MSE: 0.0110\n",
      "Validation Errors: 11\n",
      "Validation Confusion Matrix:\n",
      "[[630   0]\n",
      " [ 11  11]]\n",
      "\n",
      "Test Accuracy: 0.9832\n",
      "Test Precision: 0.9286\n",
      "Test Recall: 0.5652\n",
      "Test F1 Score: 0.7027\n",
      "Test MSE: 0.0115\n",
      "Test Errors: 11\n",
      "Test Confusion Matrix:\n",
      "[[629   1]\n",
      " [ 10  13]]\n",
      "\n",
      "\n",
      "--- Training Ganglioglioma vs Rest ---\n",
      "\n",
      "--- Evaluation for Ganglioglioma ---\n",
      "Train Accuracy: 0.9277\n",
      "Train Precision: 1.0000\n",
      "Train Recall: 0.8555\n",
      "Train F1 Score: 0.9221\n",
      "Train MSE: 0.0590\n",
      "Train Errors: 220\n",
      "Train Confusion Matrix:\n",
      "[[1521    0]\n",
      " [ 220 1302]]\n",
      "\n",
      "Validation Accuracy: 0.9985\n",
      "Validation Precision: 1.0000\n",
      "Validation Recall: 0.8889\n",
      "Validation F1 Score: 0.9412\n",
      "Validation MSE: 0.0012\n",
      "Validation Errors: 1\n",
      "Validation Confusion Matrix:\n",
      "[[643   0]\n",
      " [  1   8]]\n",
      "\n",
      "Test Accuracy: 1.0000\n",
      "Test Precision: 1.0000\n",
      "Test Recall: 1.0000\n",
      "Test F1 Score: 1.0000\n",
      "Test MSE: 0.0001\n",
      "Test Errors: 0\n",
      "Test Confusion Matrix:\n",
      "[[644   0]\n",
      " [  0   9]]\n",
      "\n",
      "\n",
      "--- Training Germinoma vs Rest ---\n",
      "\n",
      "--- Evaluation for Germinoma ---\n",
      "Train Accuracy: 0.9911\n",
      "Train Precision: 0.9973\n",
      "Train Recall: 0.9847\n",
      "Train F1 Score: 0.9909\n",
      "Train MSE: 0.0050\n",
      "Train Errors: 27\n",
      "Train Confusion Matrix:\n",
      "[[1540    4]\n",
      " [  23 1476]]\n",
      "\n",
      "Validation Accuracy: 0.9969\n",
      "Validation Precision: 0.8750\n",
      "Validation Recall: 1.0000\n",
      "Validation F1 Score: 0.9333\n",
      "Validation MSE: 0.0035\n",
      "Validation Errors: 2\n",
      "Validation Confusion Matrix:\n",
      "[[636   2]\n",
      " [  0  14]]\n",
      "\n",
      "Test Accuracy: 0.9969\n",
      "Test Precision: 0.8824\n",
      "Test Recall: 1.0000\n",
      "Test F1 Score: 0.9375\n",
      "Test MSE: 0.0026\n",
      "Test Errors: 2\n",
      "Test Confusion Matrix:\n",
      "[[636   2]\n",
      " [  0  15]]\n",
      "\n",
      "\n",
      "--- Training Glioblastoma vs Rest ---\n",
      "\n",
      "--- Evaluation for Glioblastoma ---\n",
      "Train Accuracy: 0.9251\n",
      "Train Precision: 0.9952\n",
      "Train Recall: 0.8494\n",
      "Train F1 Score: 0.9165\n",
      "Train MSE: 0.0560\n",
      "Train Errors: 228\n",
      "Train Confusion Matrix:\n",
      "[[1563    6]\n",
      " [ 222 1252]]\n",
      "\n",
      "Validation Accuracy: 0.9877\n",
      "Validation Precision: 0.8889\n",
      "Validation Recall: 0.8276\n",
      "Validation F1 Score: 0.8571\n",
      "Validation MSE: 0.0094\n",
      "Validation Errors: 8\n",
      "Validation Confusion Matrix:\n",
      "[[620   3]\n",
      " [  5  24]]\n",
      "\n",
      "Test Accuracy: 0.9893\n",
      "Test Precision: 0.9259\n",
      "Test Recall: 0.8333\n",
      "Test F1 Score: 0.8772\n",
      "Test MSE: 0.0096\n",
      "Test Errors: 7\n",
      "Test Confusion Matrix:\n",
      "[[621   2]\n",
      " [  5  25]]\n",
      "\n",
      "\n",
      "--- Training Granuloma vs Rest ---\n",
      "\n",
      "--- Evaluation for Granuloma ---\n",
      "Train Accuracy: 0.5912\n",
      "Train Precision: 1.0000\n",
      "Train Recall: 0.1827\n",
      "Train F1 Score: 0.3089\n",
      "Train MSE: 0.3579\n",
      "Train Errors: 1244\n",
      "Train Confusion Matrix:\n",
      "[[1521    0]\n",
      " [1244  278]]\n",
      "\n",
      "Validation Accuracy: 0.9862\n",
      "Validation Precision: 1.0000\n",
      "Validation Recall: 0.1818\n",
      "Validation F1 Score: 0.3077\n",
      "Validation MSE: 0.0139\n",
      "Validation Errors: 9\n",
      "Validation Confusion Matrix:\n",
      "[[641   0]\n",
      " [  9   2]]\n",
      "\n",
      "Test Accuracy: 0.9847\n",
      "Test Precision: 1.0000\n",
      "Test Recall: 0.1667\n",
      "Test F1 Score: 0.2857\n",
      "Test MSE: 0.0150\n",
      "Test Errors: 10\n",
      "Test Confusion Matrix:\n",
      "[[641   0]\n",
      " [ 10   2]]\n",
      "\n",
      "\n",
      "--- Training Meduloblastoma vs Rest ---\n",
      "\n",
      "--- Evaluation for Meduloblastoma ---\n",
      "Train Accuracy: 0.9254\n",
      "Train Precision: 0.9949\n",
      "Train Recall: 0.8608\n",
      "Train F1 Score: 0.9230\n",
      "Train MSE: 0.0479\n",
      "Train Errors: 227\n",
      "Train Confusion Matrix:\n",
      "[[1456    7]\n",
      " [ 220 1360]]\n",
      "\n",
      "Validation Accuracy: 0.9954\n",
      "Validation Precision: 1.0000\n",
      "Validation Recall: 0.8421\n",
      "Validation F1 Score: 0.9143\n",
      "Validation MSE: 0.0035\n",
      "Validation Errors: 3\n",
      "Validation Confusion Matrix:\n",
      "[[633   0]\n",
      " [  3  16]]\n",
      "\n",
      "Test Accuracy: 0.9847\n",
      "Test Precision: 0.6800\n",
      "Test Recall: 0.8947\n",
      "Test F1 Score: 0.7727\n",
      "Test MSE: 0.0111\n",
      "Test Errors: 10\n",
      "Test Confusion Matrix:\n",
      "[[626   8]\n",
      " [  2  17]]\n",
      "\n",
      "\n",
      "--- Training Meningioma vs Rest ---\n",
      "\n",
      "--- Evaluation for Meningioma ---\n",
      "Train Accuracy: 0.8403\n",
      "Train Precision: 0.9083\n",
      "Train Recall: 0.7564\n",
      "Train F1 Score: 0.8254\n",
      "Train MSE: 0.1129\n",
      "Train Errors: 486\n",
      "Train Confusion Matrix:\n",
      "[[1408  116]\n",
      " [ 370 1149]]\n",
      "\n",
      "Validation Accuracy: 0.9218\n",
      "Validation Precision: 0.8145\n",
      "Validation Recall: 0.7829\n",
      "Validation F1 Score: 0.7984\n",
      "Validation MSE: 0.0666\n",
      "Validation Errors: 51\n",
      "Validation Confusion Matrix:\n",
      "[[500  23]\n",
      " [ 28 101]]\n",
      "\n",
      "Test Accuracy: 0.9204\n",
      "Test Precision: 0.7955\n",
      "Test Recall: 0.8077\n",
      "Test F1 Score: 0.8015\n",
      "Test MSE: 0.0603\n",
      "Test Errors: 52\n",
      "Test Confusion Matrix:\n",
      "[[496  27]\n",
      " [ 25 105]]\n",
      "\n",
      "\n",
      "--- Training NORMAL vs Rest ---\n",
      "\n",
      "--- Evaluation for NORMAL ---\n",
      "Train Accuracy: 0.9353\n",
      "Train Precision: 0.9477\n",
      "Train Recall: 0.9223\n",
      "Train F1 Score: 0.9348\n",
      "Train MSE: 0.0541\n",
      "Train Errors: 197\n",
      "Train Confusion Matrix:\n",
      "[[1433   78]\n",
      " [ 119 1413]]\n",
      "\n",
      "Validation Accuracy: 0.9294\n",
      "Validation Precision: 0.6333\n",
      "Validation Recall: 0.9744\n",
      "Validation F1 Score: 0.7677\n",
      "Validation MSE: 0.0504\n",
      "Validation Errors: 46\n",
      "Validation Confusion Matrix:\n",
      "[[530  44]\n",
      " [  2  76]]\n",
      "\n",
      "Test Accuracy: 0.9464\n",
      "Test Precision: 0.7075\n",
      "Test Recall: 0.9494\n",
      "Test F1 Score: 0.8108\n",
      "Test MSE: 0.0441\n",
      "Test Errors: 35\n",
      "Test Confusion Matrix:\n",
      "[[543  31]\n",
      " [  4  75]]\n",
      "\n",
      "\n",
      "--- Training Neurocitoma vs Rest ---\n",
      "\n",
      "--- Evaluation for Neurocitoma ---\n",
      "Train Accuracy: 0.9264\n",
      "Train Precision: 0.9593\n",
      "Train Recall: 0.8847\n",
      "Train F1 Score: 0.9205\n",
      "Train MSE: 0.0619\n",
      "Train Errors: 224\n",
      "Train Confusion Matrix:\n",
      "[[1522   55]\n",
      " [ 169 1297]]\n",
      "\n",
      "Validation Accuracy: 0.9463\n",
      "Validation Precision: 0.6988\n",
      "Validation Recall: 0.8529\n",
      "Validation F1 Score: 0.7682\n",
      "Validation MSE: 0.0404\n",
      "Validation Errors: 35\n",
      "Validation Confusion Matrix:\n",
      "[[559  25]\n",
      " [ 10  58]]\n",
      "\n",
      "Test Accuracy: 0.9433\n",
      "Test Precision: 0.7000\n",
      "Test Recall: 0.8116\n",
      "Test F1 Score: 0.7517\n",
      "Test MSE: 0.0401\n",
      "Test Errors: 37\n",
      "Test Confusion Matrix:\n",
      "[[560  24]\n",
      " [ 13  56]]\n",
      "\n",
      "\n",
      "--- Training Oligodendroglioma vs Rest ---\n",
      "\n",
      "--- Evaluation for Oligodendroglioma ---\n",
      "Train Accuracy: 0.6126\n",
      "Train Precision: 1.0000\n",
      "Train Recall: 0.2119\n",
      "Train F1 Score: 0.3497\n",
      "Train MSE: 0.2790\n",
      "Train Errors: 1179\n",
      "Train Confusion Matrix:\n",
      "[[1547    0]\n",
      " [1179  317]]\n",
      "\n",
      "Validation Accuracy: 0.9709\n",
      "Validation Precision: 1.0000\n",
      "Validation Recall: 0.4242\n",
      "Validation F1 Score: 0.5957\n",
      "Validation MSE: 0.0236\n",
      "Validation Errors: 19\n",
      "Validation Confusion Matrix:\n",
      "[[619   0]\n",
      " [ 19  14]]\n",
      "\n",
      "Test Accuracy: 0.9617\n",
      "Test Precision: 1.0000\n",
      "Test Recall: 0.2424\n",
      "Test F1 Score: 0.3902\n",
      "Test MSE: 0.0301\n",
      "Test Errors: 25\n",
      "Test Confusion Matrix:\n",
      "[[620   0]\n",
      " [ 25   8]]\n",
      "\n",
      "\n",
      "--- Training Papiloma vs Rest ---\n",
      "\n",
      "--- Evaluation for Papiloma ---\n",
      "Train Accuracy: 0.7706\n",
      "Train Precision: 0.9966\n",
      "Train Recall: 0.5565\n",
      "Train F1 Score: 0.7142\n",
      "Train MSE: 0.1597\n",
      "Train Errors: 698\n",
      "Train Confusion Matrix:\n",
      "[[1473    3]\n",
      " [ 695  872]]\n",
      "\n",
      "Validation Accuracy: 0.9739\n",
      "Validation Precision: 0.9474\n",
      "Validation Recall: 0.5294\n",
      "Validation F1 Score: 0.6792\n",
      "Validation MSE: 0.0175\n",
      "Validation Errors: 17\n",
      "Validation Confusion Matrix:\n",
      "[[617   1]\n",
      " [ 16  18]]\n",
      "\n",
      "Test Accuracy: 0.9770\n",
      "Test Precision: 1.0000\n",
      "Test Recall: 0.5588\n",
      "Test F1 Score: 0.7170\n",
      "Test MSE: 0.0151\n",
      "Test Errors: 15\n",
      "Test Confusion Matrix:\n",
      "[[619   0]\n",
      " [ 15  19]]\n",
      "\n",
      "\n",
      "--- Training Schwannoma vs Rest ---\n",
      "\n",
      "--- Evaluation for Schwannoma ---\n",
      "Train Accuracy: 0.8932\n",
      "Train Precision: 0.9724\n",
      "Train Recall: 0.8047\n",
      "Train F1 Score: 0.8806\n",
      "Train MSE: 0.0742\n",
      "Train Errors: 325\n",
      "Train Confusion Matrix:\n",
      "[[1519   34]\n",
      " [ 291 1199]]\n",
      "\n",
      "Validation Accuracy: 0.9770\n",
      "Validation Precision: 0.9077\n",
      "Validation Recall: 0.8676\n",
      "Validation F1 Score: 0.8872\n",
      "Validation MSE: 0.0192\n",
      "Validation Errors: 15\n",
      "Validation Confusion Matrix:\n",
      "[[578   6]\n",
      " [  9  59]]\n",
      "\n",
      "Test Accuracy: 0.9709\n",
      "Test Precision: 0.8451\n",
      "Test Recall: 0.8824\n",
      "Test F1 Score: 0.8633\n",
      "Test MSE: 0.0263\n",
      "Test Errors: 19\n",
      "Test Confusion Matrix:\n",
      "[[574  11]\n",
      " [  8  60]]\n",
      "\n",
      "\n",
      "--- Training Tuberculoma vs Rest ---\n",
      "\n",
      "--- Evaluation for Tuberculoma ---\n",
      "Train Accuracy: 0.8429\n",
      "Train Precision: 0.9885\n",
      "Train Recall: 0.7057\n",
      "Train F1 Score: 0.8235\n",
      "Train MSE: 0.1316\n",
      "Train Errors: 478\n",
      "Train Confusion Matrix:\n",
      "[[1450   13]\n",
      " [ 465 1115]]\n",
      "\n",
      "Validation Accuracy: 0.9755\n",
      "Validation Precision: 0.5909\n",
      "Validation Recall: 0.6500\n",
      "Validation F1 Score: 0.6190\n",
      "Validation MSE: 0.0198\n",
      "Validation Errors: 16\n",
      "Validation Confusion Matrix:\n",
      "[[623   9]\n",
      " [  7  13]]\n",
      "\n",
      "Test Accuracy: 0.9724\n",
      "Test Precision: 0.5652\n",
      "Test Recall: 0.6190\n",
      "Test F1 Score: 0.5909\n",
      "Test MSE: 0.0226\n",
      "Test Errors: 18\n",
      "Test Confusion Matrix:\n",
      "[[622  10]\n",
      " [  8  13]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cls in class_names:\n",
    "    model_path = MODEL_SAVE_DIR / f\"best_binary_{cls}.pth\"\n",
    "    print(f\"\\n--- Training {cls} vs Rest ---\")\n",
    "    ds = BinaryFolderDataset(DATA_DIR, cls, transform=transform)\n",
    "    labels = [label for _, label in ds.samples]\n",
    "    \n",
    "    train_idx, temp_idx = train_test_split(range(len(ds)), test_size=0.3, stratify=labels)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, stratify=[labels[i] for i in temp_idx])\n",
    "    \n",
    "    train_loader = create_balanced_loader(ds, train_idx, BATCH_SIZE, NUM_WORKERS)\n",
    "    val_loader = DataLoader(Subset(ds, val_idx), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    test_loader = DataLoader(Subset(ds, test_idx), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    model = create_binary_model()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    # for epoch in range(1, EPOCHS + 1):\n",
    "    #     train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    #     val_metrics = eval_epoch(model, val_loader, criterion)\n",
    "    #     val_loss = val_metrics[\"loss\"]\n",
    "    #     val_acc = val_metrics[\"acc\"]\n",
    "    #     binary_histories[cls].append(val_acc)\n",
    "    #     save_binary_histories_to_csv(binary_histories)\n",
    "    #     print(f\"[{cls}] Epoch {epoch}: Val Acc = {val_acc:.4f}\")\n",
    "    #     if val_acc > best_acc:\n",
    "    #         best_acc = val_acc\n",
    "    #         torch.save(model.state_dict(), model_path)\n",
    "    ensemble_models[cls] = model\n",
    "    print(f\"\\n--- Evaluation for {cls} ---\")\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    train_metrics = eval_epoch(model, train_loader, criterion)\n",
    "    val_metrics = eval_epoch(model, val_loader, criterion)\n",
    "    test_metrics = eval_epoch(model, test_loader, criterion)\n",
    "\n",
    "    def print_metrics(split, metrics):\n",
    "        print(f\"{split} Accuracy: {metrics['acc']:.4f}\")\n",
    "        print(f\"{split} Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"{split} Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"{split} F1 Score: {metrics['f1']:.4f}\")\n",
    "        print(f\"{split} MSE: {metrics['mse']:.4f}\")\n",
    "        print(f\"{split} Errors: {metrics['errors']}\")\n",
    "        print(f\"{split} Confusion Matrix:\\n{metrics['confusion_matrix']}\\n\")\n",
    "\n",
    "    print_metrics(\"Train\", train_metrics)\n",
    "    print_metrics(\"Validation\", val_metrics)\n",
    "    print_metrics(\"Test\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e209f841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 138,357,544\n",
      "Total trainable parameters: 171,176\n",
      "Total trainable parameters: 13,649,388\n",
      "Total trainable parameters: 171,176\n",
      "Total trainable parameters: 5,182,508\n",
      "Total trainable parameters: 171,176\n",
      "808.2765340935645\n",
      "79.73891199700893\n",
      "30.275903163994954\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class LightTumorCNN2(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(LightTumorCNN2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2),  # 112x112\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),  # 56x56\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),  # 28x28\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2),  # 14x14\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x  # shape [B, 1]\n",
    "def count_trainable_params(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable parameters: {total_params:,}\")\n",
    "    return total_params\n",
    "import timm\n",
    "model1 = timm.create_model('ghostnet_100', pretrained=False, num_classes=1000)\n",
    "model2 = LightTumorCNN2(num_classes=1000)\n",
    "model3 = timm.create_model('efficientnetv2_rw_t', pretrained=False, num_classes=1000)  \n",
    "model4 = timm.create_model('vgg16', pretrained=False, num_classes=1000) \n",
    "x = count_trainable_params(model4)/count_trainable_params(model2)\n",
    "x2 = count_trainable_params(model3)/count_trainable_params(model2)\n",
    "x3 = count_trainable_params(model1)/count_trainable_params(model2)\n",
    "print(x)\n",
    "print(x2)\n",
    "print(x3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
